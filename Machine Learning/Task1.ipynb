{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b7566aa3",
   "metadata": {},
   "source": [
    "MOVIE GENRE CLASSIFICATION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73975aab",
   "metadata": {},
   "source": [
    "1: Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ff76dcf7-3929-4278-91fa-43e6363d02fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC  # Use LinearSVC for faster training\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32e38246",
   "metadata": {},
   "source": [
    "2: Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "31cc82c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Load the training, testing, and solutions data\n",
    "column_names_train = [\"ID\", \"TITLE\", \"GENRE\", \"DESCRIPTION\"]\n",
    "train = pd.read_csv(r'D:\\Mustufahussain\\CodSoft\\Machine Learning\\Dataset\\Genre Classification Dataset\\train_data.txt', sep=':::', names=column_names_train, engine='python')\n",
    "\n",
    "column_names_test = [\"ID\", \"TITLE\", \"DESCRIPTION\"]\n",
    "test = pd.read_csv(r'D:\\Mustufahussain\\CodSoft\\Machine Learning\\Dataset\\Genre Classification Dataset\\test_data.txt', sep=':::', names=column_names_test, engine='python')\n",
    "\n",
    "column_names_solution = [\"ID\", \"TITLE\", \"GENRE\", \"DESCRIPTION\"]\n",
    "solutions = pd.read_csv(r'D:\\Mustufahussain\\CodSoft\\Machine Learning\\Dataset\\Genre Classification Dataset\\test_data_solution.txt', sep=':::', names=column_names_solution, engine='python')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c44aedd",
   "metadata": {},
   "source": [
    "3: Data Inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e7346cff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Missing Values in Train Data:\n",
      "ID             0\n",
      "TITLE          0\n",
      "GENRE          0\n",
      "DESCRIPTION    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# 2. Data Inspection\n",
    "print(\"\\nMissing Values in Train Data:\")\n",
    "print(train.isna().sum())  # Check for missing values in train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "624677c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Data Types in Train Data:\n",
      "ID              int64\n",
      "TITLE          object\n",
      "GENRE          object\n",
      "DESCRIPTION    object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nData Types in Train Data:\")\n",
    "print(train.dtypes)  # Check data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b9b0a5a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Missing Values in Test Data:\n",
      "ID             0\n",
      "TITLE          0\n",
      "DESCRIPTION    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nMissing Values in Test Data:\")\n",
    "print(test.isna().sum())  # Check for missing values in test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3f355bfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Data Types in Test Data:\n",
      "ID              int64\n",
      "TITLE          object\n",
      "DESCRIPTION    object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nData Types in Test Data:\")\n",
    "print(test.dtypes)  # Check data types in test data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78b22dd7",
   "metadata": {},
   "source": [
    "4: Fill Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8a49e7ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Handling missing values in datasets...\n",
      "\n",
      "Missing values after handling:\n",
      "Train Data:\n",
      "ID             0\n",
      "TITLE          0\n",
      "GENRE          0\n",
      "DESCRIPTION    0\n",
      "dtype: int64\n",
      "\n",
      "Test Data:\n",
      "ID             0\n",
      "TITLE          0\n",
      "DESCRIPTION    0\n",
      "dtype: int64\n",
      "\n",
      "Solutions Data:\n",
      "ID             0\n",
      "TITLE          0\n",
      "GENRE          0\n",
      "DESCRIPTION    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# 3. Fill missing values (if any)\n",
    "print(\"Handling missing values in datasets...\")\n",
    "train['DESCRIPTION'] = train['DESCRIPTION'].fillna('No description available')\n",
    "train['GENRE'] = train['GENRE'].fillna('Unknown')\n",
    "test['DESCRIPTION'] = test['DESCRIPTION'].fillna('No description available')\n",
    "solutions['GENRE'] = solutions['GENRE'].fillna('Unknown')\n",
    "\n",
    "# Print the number of missing values after filling\n",
    "print(\"\\nMissing values after handling:\")\n",
    "print(f\"Train Data:\\n{train.isna().sum()}\")\n",
    "print(f\"\\nTest Data:\\n{test.isna().sum()}\")\n",
    "print(f\"\\nSolutions Data:\\n{solutions.isna().sum()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3938f920",
   "metadata": {},
   "source": [
    "5: TF-IDF Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "412aff9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorizing text data using TF-IDF...\n",
      "\n",
      "TF-IDF Vectorization Complete.\n",
      "Shape of Train TF-IDF Matrix: (54214, 5000)\n",
      "Shape of Test TF-IDF Matrix: (54200, 5000)\n"
     ]
    }
   ],
   "source": [
    "# 4. Vectorization using TF-IDF\n",
    "print(\"Vectorizing text data using TF-IDF...\")\n",
    "vectorizer = TfidfVectorizer(stop_words='english', max_features=5000)\n",
    "X_train_tfidf = vectorizer.fit_transform(train['DESCRIPTION'])\n",
    "X_test_tfidf = vectorizer.transform(test['DESCRIPTION'])\n",
    "\n",
    "# Print the shape of the TF-IDF matrices\n",
    "print(\"\\nTF-IDF Vectorization Complete.\")\n",
    "print(f\"Shape of Train TF-IDF Matrix: {X_train_tfidf.shape}\")\n",
    "print(f\"Shape of Test TF-IDF Matrix: {X_test_tfidf.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be78c64d",
   "metadata": {},
   "source": [
    "6: Naive Bayes Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3db060bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Naive Bayes...\n",
      "\n",
      "Naive Bayes Model Evaluation (on Test Split):\n",
      "Accuracy: 0.52310246241815\n",
      "Confusion Matrix:\n",
      "[[  21    0    0    0    0   19    0   51  155    0    0    0    0    8\n",
      "     0    0    0    0    0    0    0    3    3    0    2    0    1]\n",
      " [   0    7    7    0    0   35    0    8   51    0    0    0    0    1\n",
      "     0    0    0    0    0    0    0    3    0    0    0    0    0]\n",
      " [   3    1    4    0    0   15    0   35   71    0    0    0    0    6\n",
      "     0    0    0    0    0    0    0    2    0    0    1    0    1]\n",
      " [   0    0    0    0    0   23    0   37   40    0    0    0    0    1\n",
      "     0    0    0    0    0    0    0    3    0    0    0    0    0]\n",
      " [   0    0    0    0    0    2    0   42   17    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0]\n",
      " [   3    0    1    0    0  629    0  150  644    0    0    0    0    6\n",
      "     1    0    0    0    0    0    0    9    0    0    0    0    0]\n",
      " [   1    0    0    0    0    8    0    8   85    0    0    0    0    2\n",
      "     0    0    0    0    0    0    0    1    0    0    1    0    1]\n",
      " [   1    0    0    0    0   41    0 2342  254    0    0    0    0    3\n",
      "     0    0    0    0    1    0    0   16    0    0    1    0    0]\n",
      " [   4    0    0    0    0  138    0  300 2232    0    0    0    0    4\n",
      "     0    0    0    0    0    0    0   17    0    0    2    0    0]\n",
      " [   0    0    1    0    0   32    0   53   59    1    0    0    0    1\n",
      "     0    0    0    0    0    0    0    3    0    0    0    0    0]\n",
      " [   0    0    1    0    0    4    0   15   51    0    0    0    0    1\n",
      "     0    0    0    0    0    0    0    2    0    0    0    0    0]\n",
      " [   0    0    0    0    0   14    0   19    1    0    0    6    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    1    0   31   13    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0   29    0   46  187    0    0    0    0  163\n",
      "     0    0    0    0    0    0    1    4    0    0    1    0    0]\n",
      " [   0    0    0    0    0    9    0  112    5    0    0    0    0    0\n",
      "    15    0    0    0    0    0    0    3    0    0    0    0    0]\n",
      " [   0    0    0    0    0   10    0   15   23    0    0    0    0    0\n",
      "     2    0    0    0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    3    0    7   42    0    0    0    0    2\n",
      "     0    0    0    0    0    0    0    0    0    0    2    0    0]\n",
      " [   0    0    0    0    0    1    0   32    1    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0   53    0  116   16    0    0    0    0    0\n",
      "     0    0    0    0    4    0    0    3    0    0    0    0    0]\n",
      " [   0    0    0    0    0   14    0    8  129    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0]\n",
      " [   1    0    0    0    0   10    0   66   46    0    0    0    0    8\n",
      "     0    0    0    0    0    0    6    5    0    0    1    0    0]\n",
      " [   0    0    0    0    0   91    0  401  438    0    0    0    0    3\n",
      "     1    0    0    0    0    0    0  111    0    0    0    0    0]\n",
      " [   0    0    0    0    0    8    0   73    2    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    2    8    0    0    0    0]\n",
      " [   0    0    0    0    0    9    0   68    3    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    1    0    0    0    0    0]\n",
      " [   2    0    0    0    0   20    0   19  248    0    0    0    0   15\n",
      "     0    0    0    0    0    0    0    1    0    0    4    0    0]\n",
      " [   1    0    0    0    0    1    0    9    9    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    9    0    4   68    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0  119]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "      action        0.57      0.08      0.14       263\n",
      "       adult        0.88      0.06      0.12       112\n",
      "   adventure        0.29      0.03      0.05       139\n",
      "   animation        0.00      0.00      0.00       104\n",
      "   biography        0.00      0.00      0.00        61\n",
      "      comedy        0.51      0.44      0.47      1443\n",
      "       crime        0.00      0.00      0.00       107\n",
      " documentary        0.58      0.88      0.70      2659\n",
      "       drama        0.46      0.83      0.59      2697\n",
      "      family        1.00      0.01      0.01       150\n",
      "     fantasy        0.00      0.00      0.00        74\n",
      "   game-show        1.00      0.15      0.26        40\n",
      "     history        0.00      0.00      0.00        45\n",
      "      horror        0.73      0.38      0.50       431\n",
      "       music        0.79      0.10      0.18       144\n",
      "     musical        0.00      0.00      0.00        50\n",
      "     mystery        0.00      0.00      0.00        56\n",
      "        news        0.00      0.00      0.00        34\n",
      "  reality-tv        0.80      0.02      0.04       192\n",
      "     romance        0.00      0.00      0.00       151\n",
      "      sci-fi        0.86      0.04      0.08       143\n",
      "       short        0.59      0.11      0.18      1045\n",
      "       sport        0.73      0.09      0.15        93\n",
      "   talk-show        0.00      0.00      0.00        81\n",
      "    thriller        0.27      0.01      0.02       309\n",
      "         war        0.00      0.00      0.00        20\n",
      "     western        0.98      0.59      0.74       200\n",
      "\n",
      "     accuracy                           0.52     10843\n",
      "    macro avg       0.41      0.14      0.16     10843\n",
      " weighted avg       0.52      0.52      0.44     10843\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 7. Define and train the Naive Bayes model\n",
    "print(\"\\nTraining Naive Bayes...\")\n",
    "naive_bayes_model = MultinomialNB()\n",
    "naive_bayes_model.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred_nb = naive_bayes_model.predict(X_test)\n",
    "\n",
    "# Evaluation\n",
    "accuracy_nb = accuracy_score(y_test, y_pred_nb)\n",
    "conf_matrix_nb = confusion_matrix(y_test, y_pred_nb)\n",
    "\n",
    "# Adjust classification report to handle undefined metrics\n",
    "class_report_nb = classification_report(y_test, y_pred_nb, zero_division=0)\n",
    "\n",
    "# Display the results\n",
    "print(\"\\nNaive Bayes Model Evaluation (on Test Split):\")\n",
    "print(f'Accuracy: {accuracy_nb}')\n",
    "print(f'Confusion Matrix:\\n{conf_matrix_nb}')\n",
    "print(f'Classification Report:\\n{class_report_nb}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93cf97af",
   "metadata": {},
   "source": [
    "7: Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4df8fd5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Logistic Regression...\n",
      "\n",
      "Logistic Regression Model Evaluation (on Test Split):\n",
      "Accuracy: 0.5795444065295582\n",
      "Confusion Matrix:\n",
      "[[  68    0    1    0    0   26    2   32   94    0    0    0    0   12\n",
      "     0    0    0    0    0    0    5    5    5    0   13    0    0]\n",
      " [   0   24   13    0    0   32    0    6   27    0    0    0    0    1\n",
      "     0    0    0    0    0    0    0    7    0    0    1    0    1]\n",
      " [   6    0   19    0    0   20    0   27   37    1    0    0    0   10\n",
      "     0    0    0    0    1    0    4    9    1    0    2    0    2]\n",
      " [   1    0    2    9    0   22    0   17   23    9    1    0    0    2\n",
      "     1    0    0    0    0    0    6   11    0    0    0    0    0]\n",
      " [   0    0    0    0    0    2    0   38   18    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    3    0    0    0    0    0]\n",
      " [   6    1    1    1    0  845    1   91  414    2    0    0    0   11\n",
      "     2    0    0    0    7    1    1   49    2    1    4    0    3]\n",
      " [   7    0    0    0    0   20    2   13   46    0    0    0    0    6\n",
      "     0    0    0    0    0    0    1    4    0    0    8    0    0]\n",
      " [   3    1    1    0    0   60    0 2243  214    0    0    0    0   11\n",
      "    21    0    0    0    8    0    1   92    1    0    3    0    0]\n",
      " [   9    1    2    0    0  242    1  220 2106    2    0    0    0   17\n",
      "     1    0    0    0    2    4    0   74    2    0   13    0    1]\n",
      " [   0    0    3    2    0   34    0   30   49   11    1    0    0    1\n",
      "     4    0    0    0    2    0    0   12    0    1    0    0    0]\n",
      " [   3    1    4    1    0   11    0   10   26    0    0    0    0    5\n",
      "     0    0    0    0    0    0    1   12    0    0    0    0    0]\n",
      " [   0    0    0    0    0   11    0    6    1    0    0   17    0    0\n",
      "     0    0    0    0    4    0    0    0    1    0    0    0    0]\n",
      " [   0    0    0    0    0    1    0   28   16    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0]\n",
      " [   5    0    0    0    0   30    0   28   90    1    0    0    0  241\n",
      "     1    0    0    0    1    0    4   19    0    1   10    0    0]\n",
      " [   0    0    0    0    0   10    0   43    9    0    0    0    0    0\n",
      "    70    0    0    0    1    0    0   11    0    0    0    0    0]\n",
      " [   0    0    0    0    0    7    0    6   24    0    0    0    0    1\n",
      "     6    1    0    0    0    0    0    4    0    0    0    0    1]\n",
      " [   0    0    0    0    0    5    1    4   25    0    0    0    0    6\n",
      "     0    0    0    0    0    0    0    3    0    0   12    0    0]\n",
      " [   0    0    0    0    0    4    0   26    0    0    0    0    0    0\n",
      "     0    0    0    2    1    0    0    0    0    1    0    0    0]\n",
      " [   0    1    0    0    0   45    0   81   17    2    0    0    0    1\n",
      "     1    0    0    0   35    0    0    9    0    0    0    0    0]\n",
      " [   0    1    0    0    0   30    0    2  108    0    0    0    0    0\n",
      "     0    0    0    0    0    1    0    9    0    0    0    0    0]\n",
      " [   4    0    0    0    0   16    0   30   33    0    0    0    0    9\n",
      "     0    0    0    0    2    0   31   15    0    0    3    0    0]\n",
      " [   3    0    0    2    0  114    0  280  287    0    0    0    0   10\n",
      "     2    0    0    0    0    0    0  345    0    0    2    0    0]\n",
      " [   3    0    0    0    0    9    0   52    3    0    0    0    0    0\n",
      "     0    0    0    0    1    0    0    5   18    2    0    0    0]\n",
      " [   0    0    0    0    0   10    0   42    3    0    0    0    0    0\n",
      "     2    0    0    0    7    0    0    7    0   10    0    0    0]\n",
      " [  11    2    0    0    0   27    0   20  157    0    0    1    0   31\n",
      "     0    0    0    0    0    0    0   15    0    0   45    0    0]\n",
      " [   1    0    0    0    0    0    0    6    9    0    0    0    0    0\n",
      "     0    0    0    0    1    0    0    3    0    0    0    0    0]\n",
      " [   2    0    0    0    0   11    0    2   40    0    0    0    0    2\n",
      "     0    0    0    0    0    0    0    1    0    0    1    0  141]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "      action        0.52      0.26      0.34       263\n",
      "       adult        0.75      0.21      0.33       112\n",
      "   adventure        0.41      0.14      0.21       139\n",
      "   animation        0.60      0.09      0.15       104\n",
      "   biography        0.00      0.00      0.00        61\n",
      "      comedy        0.51      0.59      0.55      1443\n",
      "       crime        0.29      0.02      0.04       107\n",
      " documentary        0.66      0.84      0.74      2659\n",
      "       drama        0.54      0.78      0.64      2697\n",
      "      family        0.39      0.07      0.12       150\n",
      "     fantasy        0.00      0.00      0.00        74\n",
      "   game-show        0.94      0.42      0.59        40\n",
      "     history        0.00      0.00      0.00        45\n",
      "      horror        0.64      0.56      0.60       431\n",
      "       music        0.63      0.49      0.55       144\n",
      "     musical        1.00      0.02      0.04        50\n",
      "     mystery        0.00      0.00      0.00        56\n",
      "        news        1.00      0.06      0.11        34\n",
      "  reality-tv        0.48      0.18      0.26       192\n",
      "     romance        0.17      0.01      0.01       151\n",
      "      sci-fi        0.57      0.22      0.31       143\n",
      "       short        0.48      0.33      0.39      1045\n",
      "       sport        0.60      0.19      0.29        93\n",
      "   talk-show        0.62      0.12      0.21        81\n",
      "    thriller        0.38      0.15      0.21       309\n",
      "         war        0.00      0.00      0.00        20\n",
      "     western        0.95      0.70      0.81       200\n",
      "\n",
      "     accuracy                           0.58     10843\n",
      "    macro avg       0.49      0.24      0.28     10843\n",
      " weighted avg       0.55      0.58      0.54     10843\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 7. Define and train the Logistic Regression model\n",
    "print(\"\\nTraining Logistic Regression...\")\n",
    "log_reg_model = LogisticRegression(max_iter=1000)\n",
    "log_reg_model.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred_lr = log_reg_model.predict(X_test)\n",
    "\n",
    "# Evaluation\n",
    "accuracy_lr = accuracy_score(y_test, y_pred_lr)\n",
    "conf_matrix_lr = confusion_matrix(y_test, y_pred_lr)\n",
    "\n",
    "# Adjust classification report to handle undefined metrics\n",
    "class_report_lr = classification_report(y_test, y_pred_lr, zero_division=0)\n",
    "\n",
    "# Display the results\n",
    "print(\"\\nLogistic Regression Model Evaluation (on Test Split):\")\n",
    "print(f'Accuracy: {accuracy_lr}')\n",
    "print(f'Confusion Matrix:\\n{conf_matrix_lr}')\n",
    "print(f'Classification Report:\\n{class_report_lr}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07d90135",
   "metadata": {},
   "source": [
    "8: SVM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6f3f895e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Support Vector Machine (SVM)...\n",
      "\n",
      "SVM Model Evaluation (on Test Split):\n",
      "Accuracy: 0.5776998985520613\n",
      "Confusion Matrix:\n",
      "[[  59    1    0    0    0   26    2   34   97    0    0    0    0   16\n",
      "     0    0    0    0    0    0    6    5    6    0    9    0    2]\n",
      " [   0   26   14    0    0   29    0    5   28    0    0    0    0    1\n",
      "     0    0    0    0    1    0    0    7    0    0    0    0    1]\n",
      " [   7    1   22    0    0   16    0   29   35    1    0    0    0   10\n",
      "     0    0    0    0    0    0    6    6    1    0    1    0    4]\n",
      " [   1    0    1   11    0   22    0   20   24    7    1    0    0    4\n",
      "     1    0    0    0    0    0    5    7    0    0    0    0    0]\n",
      " [   0    0    0    0    0    3    0   38   17    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    2    0    0    0    0    1]\n",
      " [   5    2    0    1    0  801    0  105  447    2    0    2    0   17\n",
      "     5    0    0    0    5    0    2   36    3    1    5    0    4]\n",
      " [   6    0    0    0    0   21    1   14   52    0    0    0    0    4\n",
      "     0    0    0    0    0    0    0    4    0    0    4    0    1]\n",
      " [   3    0    0    0    0   55    0 2291  196    1    0    0    0   13\n",
      "    20    0    0    0    4    0    1   69    2    0    3    0    1]\n",
      " [  10    1    1    0    0  211    1  257 2121    0    0    0    0   24\n",
      "     0    0    0    0    2    0    0   60    0    0    6    0    3]\n",
      " [   0    0    1    2    0   36    0   32   49    8    1    0    0    2\n",
      "     4    0    0    0    2    0    0   10    1    2    0    0    0]\n",
      " [   3    1    3    1    0    9    0   11   28    0    1    0    0    6\n",
      "     0    0    0    0    0    0    1    9    0    0    1    0    0]\n",
      " [   0    0    0    0    0    9    0    6    1    0    0   23    0    0\n",
      "     0    0    0    0    0    0    0    0    1    0    0    0    0]\n",
      " [   0    0    0    0    0    2    0   28   15    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0]\n",
      " [   4    0    1    0    0   26    0   27   95    1    0    0    0  255\n",
      "     0    0    0    0    1    0    3   11    0    0    7    0    0]\n",
      " [   0    0    0    0    0    9    0   52    8    0    0    0    0    0\n",
      "    66    0    0    0    1    0    0    8    0    0    0    0    0]\n",
      " [   0    0    0    1    0    7    0    6   23    0    0    0    0    1\n",
      "     6    0    0    0    0    0    0    4    0    0    0    0    2]\n",
      " [   1    0    0    0    0    4    0    6   26    0    0    0    0    6\n",
      "     0    0    1    0    0    0    0    1    0    0    9    0    2]\n",
      " [   0    0    0    1    0    3    0   26    0    0    0    0    0    0\n",
      "     0    0    0    2    1    0    0    0    0    1    0    0    0]\n",
      " [   0    1    0    0    0   49    0   83   19    1    0    1    0    2\n",
      "     1    0    0    0   26    0    0    7    0    1    0    0    1]\n",
      " [   0    1    0    0    0   29    0    4  114    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    3    0    0    0    0    0]\n",
      " [   4    0    0    0    0   13    0   36   36    0    0    0    0   12\n",
      "     0    0    0    0    1    0   28   10    0    0    3    0    0]\n",
      " [   2    0    0    3    0  115    0  307  302    1    0    0    0   13\n",
      "     3    0    0    0    1    0    0  295    0    0    2    0    1]\n",
      " [   2    0    0    0    0    7    0   54    2    0    0    0    0    0\n",
      "     0    0    0    0    1    0    0    4   21    2    0    0    0]\n",
      " [   0    0    0    0    0    8    0   43    5    0    0    1    0    1\n",
      "     2    0    0    0    4    0    0    4    0   13    0    0    0]\n",
      " [   7    1    0    0    0   29    0   23  158    0    0    1    0   38\n",
      "     0    0    0    0    0    0    1   14    0    0   36    0    1]\n",
      " [   1    0    0    0    0    1    0    7    9    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    2    0    0    0    0    0]\n",
      " [   1    0    0    0    0    7    0    3   29    0    0    0    0    1\n",
      "     0    0    0    0    0    0    0    2    0    0    0    0  157]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "      action        0.51      0.22      0.31       263\n",
      "       adult        0.74      0.23      0.35       112\n",
      "   adventure        0.51      0.16      0.24       139\n",
      "   animation        0.55      0.11      0.18       104\n",
      "   biography        0.00      0.00      0.00        61\n",
      "      comedy        0.52      0.56      0.54      1443\n",
      "       crime        0.25      0.01      0.02       107\n",
      " documentary        0.65      0.86      0.74      2659\n",
      "       drama        0.54      0.79      0.64      2697\n",
      "      family        0.36      0.05      0.09       150\n",
      "     fantasy        0.33      0.01      0.03        74\n",
      "   game-show        0.82      0.57      0.68        40\n",
      "     history        0.00      0.00      0.00        45\n",
      "      horror        0.60      0.59      0.60       431\n",
      "       music        0.61      0.46      0.52       144\n",
      "     musical        0.00      0.00      0.00        50\n",
      "     mystery        1.00      0.02      0.04        56\n",
      "        news        1.00      0.06      0.11        34\n",
      "  reality-tv        0.52      0.14      0.21       192\n",
      "     romance        0.00      0.00      0.00       151\n",
      "      sci-fi        0.53      0.20      0.29       143\n",
      "       short        0.51      0.28      0.36      1045\n",
      "       sport        0.60      0.23      0.33        93\n",
      "   talk-show        0.65      0.16      0.26        81\n",
      "    thriller        0.42      0.12      0.18       309\n",
      "         war        0.00      0.00      0.00        20\n",
      "     western        0.87      0.79      0.82       200\n",
      "\n",
      "     accuracy                           0.58     10843\n",
      "    macro avg       0.48      0.24      0.28     10843\n",
      " weighted avg       0.55      0.58      0.53     10843\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 8. Define and train the SVM model\n",
    "print(\"\\nTraining Support Vector Machine (SVM)...\")\n",
    "svm_model = LinearSVC(max_iter=1000, C=0.1, dual=False)  # Explicitly set dual to False\n",
    "svm_model.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred_svm = svm_model.predict(X_test)\n",
    "\n",
    "# Evaluation\n",
    "accuracy_svm = accuracy_score(y_test, y_pred_svm)\n",
    "conf_matrix_svm = confusion_matrix(y_test, y_pred_svm)\n",
    "\n",
    "# Adjust classification report to handle undefined metrics\n",
    "class_report_svm = classification_report(y_test, y_pred_svm, zero_division=0)\n",
    "\n",
    "# Display the results\n",
    "print(\"\\nSVM Model Evaluation (on Test Split):\")\n",
    "print(f'Accuracy: {accuracy_svm}')\n",
    "print(f'Confusion Matrix:\\n{conf_matrix_svm}')\n",
    "print(f'Classification Report:\\n{class_report_svm}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39f68b37",
   "metadata": {},
   "source": [
    "9: Test Data Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6e6fffbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Naive Bayes Predictions on Test Data:\n",
      "  genre_prediction\n",
      "0           drama \n",
      "1           drama \n",
      "2     documentary \n",
      "3           drama \n",
      "4           drama \n",
      "\n",
      "Logistic Regression Predictions on Test Data:\n",
      "  genre_prediction\n",
      "0           short \n",
      "1           drama \n",
      "2     documentary \n",
      "3           drama \n",
      "4           drama \n",
      "\n",
      "SVM Predictions on Test Data:\n",
      "  genre_prediction\n",
      "0           drama \n",
      "1           drama \n",
      "2     documentary \n",
      "3           drama \n",
      "4           drama \n"
     ]
    }
   ],
   "source": [
    "# 9. Predictions on the Test Data\n",
    "X_test_transformed = vectorizer.transform(test['DESCRIPTION'])\n",
    "\n",
    "# Make predictions with Naive Bayes\n",
    "naive_bayes_predictions = naive_bayes_model.predict(X_test_transformed)\n",
    "naive_bayes_predictions_df = pd.DataFrame(naive_bayes_predictions, columns=['genre_prediction'])\n",
    "print(\"\\nNaive Bayes Predictions on Test Data:\")\n",
    "print(naive_bayes_predictions_df.head())\n",
    "\n",
    "# Make predictions with Logistic Regression\n",
    "log_reg_predictions = log_reg_model.predict(X_test_transformed)\n",
    "log_reg_predictions_df = pd.DataFrame(log_reg_predictions, columns=['genre_prediction'])\n",
    "print(\"\\nLogistic Regression Predictions on Test Data:\")\n",
    "print(log_reg_predictions_df.head())\n",
    "\n",
    "# Make predictions with SVM\n",
    "svm_predictions = svm_model.predict(X_test_transformed)\n",
    "svm_predictions_df = pd.DataFrame(svm_predictions, columns=['genre_prediction'])\n",
    "print(\"\\nSVM Predictions on Test Data:\")\n",
    "print(svm_predictions_df.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
