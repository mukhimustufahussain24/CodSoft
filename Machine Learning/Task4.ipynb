{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SPAM SMS DETECTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1 - Importing Necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2 - Loading and Exploring the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Overview:\n",
      "     v1                                                 v2 Unnamed: 2  \\\n",
      "0   ham  Go until jurong point, crazy.. Available only ...        NaN   \n",
      "1   ham                      Ok lar... Joking wif u oni...        NaN   \n",
      "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...        NaN   \n",
      "3   ham  U dun say so early hor... U c already then say...        NaN   \n",
      "4   ham  Nah I don't think he goes to usf, he lives aro...        NaN   \n",
      "\n",
      "  Unnamed: 3 Unnamed: 4  \n",
      "0        NaN        NaN  \n",
      "1        NaN        NaN  \n",
      "2        NaN        NaN  \n",
      "3        NaN        NaN  \n",
      "4        NaN        NaN  \n"
     ]
    }
   ],
   "source": [
    "# Load the dataset with a different encoding\n",
    "file_path = 'D:/Mustufahussain/CodSoft/Machine Learning/Dataset/Spam/spam.csv'\n",
    "data = pd.read_csv(file_path, encoding='ISO-8859-1')\n",
    "\n",
    "# Display the first few rows of the dataset\n",
    "print(\"Dataset Overview:\")\n",
    "print(data.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3 - Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Preprocessing Text Data...\n",
      "\n",
      "Cleaned Dataset Preview:\n",
      "   v1                                                 v2 Unnamed: 2  \\\n",
      "0   0  go until jurong point, crazy.. available only ...        NaN   \n",
      "1   0                      ok lar... joking wif u oni...        NaN   \n",
      "2   1  free entry in 2 a wkly comp to win fa cup fina...        NaN   \n",
      "3   0  u dun say so early hor... u c already then say...        NaN   \n",
      "4   0  nah i don't think he goes to usf, he lives aro...        NaN   \n",
      "\n",
      "  Unnamed: 3 Unnamed: 4  \n",
      "0        NaN        NaN  \n",
      "1        NaN        NaN  \n",
      "2        NaN        NaN  \n",
      "3        NaN        NaN  \n",
      "4        NaN        NaN  \n"
     ]
    }
   ],
   "source": [
    "# Clean the text data: remove extra spaces, convert to lowercase\n",
    "print(\"\\nPreprocessing Text Data...\")\n",
    "\n",
    "data['v2'] = data['v2'].str.replace(r'\\s+', ' ', regex=True).str.strip().str.lower()\n",
    "\n",
    "# Encoding the labels ('ham' as 0, 'spam' as 1)\n",
    "data['v1'] = data['v1'].map({'ham': 0, 'spam': 1})\n",
    "\n",
    "# Show cleaned dataset\n",
    "print(\"\\nCleaned Dataset Preview:\")\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4 - Feature Extraction using TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting Text Data to Numerical Features using TF-IDF...\n",
      "\n",
      "Shape of X: (5572, 5000)\n"
     ]
    }
   ],
   "source": [
    "# Convert the text data into numerical features using TF-IDF\n",
    "print(\"\\nConverting Text Data to Numerical Features using TF-IDF...\")\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer(stop_words='english', max_features=5000)\n",
    "X = tfidf_vectorizer.fit_transform(data['v2'])\n",
    "y = data['v1']\n",
    "\n",
    "print(f\"\\nShape of X: {X.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5 - Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Splitting the data into training and testing sets...\n",
      "\n",
      "Shape of X_train: (4457, 5000), Shape of X_test: (1115, 5000)\n"
     ]
    }
   ],
   "source": [
    "# Split the data into training and testing sets\n",
    "print(\"\\nSplitting the data into training and testing sets...\")\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"\\nShape of X_train: {X_train.shape}, Shape of X_test: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6 - Model Training with Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Naive Bayes model...\n",
      "\n",
      "Naive Bayes Model Evaluation:\n",
      "Accuracy: 0.9757847533632287\n",
      "[[965   0]\n",
      " [ 27 123]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.99       965\n",
      "           1       1.00      0.82      0.90       150\n",
      "\n",
      "    accuracy                           0.98      1115\n",
      "   macro avg       0.99      0.91      0.94      1115\n",
      "weighted avg       0.98      0.98      0.97      1115\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train a Naive Bayes model\n",
    "print(\"\\nTraining Naive Bayes model...\")\n",
    "\n",
    "nb_model = MultinomialNB()\n",
    "nb_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "nb_predictions = nb_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"\\nNaive Bayes Model Evaluation:\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test, nb_predictions)}\")\n",
    "print(confusion_matrix(y_test, nb_predictions))\n",
    "print(classification_report(y_test, nb_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7 - Model Training with Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Logistic Regression model...\n",
      "\n",
      "Logistic Regression Model Evaluation:\n",
      "Accuracy: 0.9479820627802691\n",
      "[[962   3]\n",
      " [ 55  95]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.97       965\n",
      "           1       0.97      0.63      0.77       150\n",
      "\n",
      "    accuracy                           0.95      1115\n",
      "   macro avg       0.96      0.82      0.87      1115\n",
      "weighted avg       0.95      0.95      0.94      1115\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train a Logistic Regression model\n",
    "print(\"\\nTraining Logistic Regression model...\")\n",
    "\n",
    "log_reg_model = LogisticRegression(max_iter=1000)\n",
    "log_reg_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "log_reg_predictions = log_reg_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"\\nLogistic Regression Model Evaluation:\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test, log_reg_predictions)}\")\n",
    "print(confusion_matrix(y_test, log_reg_predictions))\n",
    "print(classification_report(y_test, log_reg_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8 - Model Training with Support Vector Machine (SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Support Vector Machine (SVM) model...\n",
      "\n",
      "Support Vector Machine (SVM) Model Evaluation:\n",
      "Accuracy: 0.9748878923766816\n",
      "[[964   1]\n",
      " [ 27 123]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.99       965\n",
      "           1       0.99      0.82      0.90       150\n",
      "\n",
      "    accuracy                           0.97      1115\n",
      "   macro avg       0.98      0.91      0.94      1115\n",
      "weighted avg       0.98      0.97      0.97      1115\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train a Support Vector Machine (SVM) model\n",
    "print(\"\\nTraining Support Vector Machine (SVM) model...\")\n",
    "\n",
    "svm_model = SVC()\n",
    "svm_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "svm_predictions = svm_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"\\nSupport Vector Machine (SVM) Model Evaluation:\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test, svm_predictions)}\")\n",
    "print(confusion_matrix(y_test, svm_predictions))\n",
    "print(classification_report(y_test, svm_predictions))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
